"""
Dataset utilities for RL4Rec
ì¶”ì²œ ì‹œìŠ¤í…œ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìœ í‹¸ë¦¬í‹°
"""

import os
import json
import pickle
import numpy as np
import argparse
from pathlib import Path
from typing import List, Dict, Optional, Tuple

import torch
from torch.utils.data import Dataset, DataLoader


class PromptGenerator:
    """
    ì‚¬ìš©ì ì‹œí€€ìŠ¤ë¡œë¶€í„° í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤
    
    ì§€ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ íƒ€ì…:
    - 'preference': ì‚¬ìš©ì ì„ í˜¸ë„ ë¬˜ì‚¬
    - 'next_item': ë‹¤ìŒ ì•„ì´í…œ ì˜ˆì¸¡
    - 'recommendation': ì¶”ì²œ ì•„ì´í…œ ìƒì„±
    - 'user_profile': ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
    - 'recent_preference': ìµœê·¼ ì„ í˜¸ë„ ë¬˜ì‚¬
    """
    
    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    PROMPT_TEMPLATES = {
        'seq_rec': {
        'title': 'You are an intelligent shopping assistant that helps predict what users may want to purchase next. Below is a list of items a user has purchased recently.\n' +\
                   'Your task is to infer one or multiple kinds of products they may want to buy next, and generate relevant query terms that can be used to search for these potential products.\n' +\
                   'Below is the user purchase history:\n',
        'task': 'Based on this user\'s purchase history, generate relevant query terms that can be used to search for these potential products.',
        },
        'preference': {
            'title': '# User Purchase History',
            'task': '# Task\nBased on this user\'s purchase history, describe user\'s preference:',
        },
        'next_item': {
            'title': '# User Purchase History',
            'task': '# Task\nBased on this user\'s purchase history, predict what item the user will purchase next:',
        },
        'recommendation': {
            'title': '# User Purchase History',
            'task': '# Task\nBased on this user\'s purchase history, recommend suitable items for the user:',
        },
        'user_profile': {
            'title': '# User Purchase History',
            'task': '# Task\nBased on this user\'s purchase history, create a detailed user profile describing their interests and preferences:',
        },
        'recent_preference': {
            'title': '# User Purchase History',
            'task': '# Task\nBased on this user\'s purchase history, describe user\'s most recent preference:',
        },
    }
    
    def __init__(
        self,
        item_metadata: Dict,
        data_name: str = None,
        prompt_type: str = 'seq_rec',
        use_brand: bool = True,
        use_category: bool = True,
        use_description: bool = False,
        use_features: bool = False,
        use_last_item: bool = True,
        use_date: bool = True,
        max_history_len: int = 5,
        history_text_max_length: int = 100,
        use_reviews: bool = False,
        days_filter: int = None,
    ):
        """
        Args:
            item_metadata: ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            data_name: ë°ì´í„°ì…‹ ì´ë¦„ (ë‚ ì§œ ì •ë³´ ë¡œë“œì— ì‚¬ìš©)
            prompt_type: í”„ë¡¬í”„íŠ¸ íƒ€ì… ('preference', 'next_item', 'recommendation', 'user_profile', 'recent_preference', 'reasoning')
            use_brand: ë¸Œëœë“œ ì •ë³´ í¬í•¨ ì—¬ë¶€
            use_category: ì¹´í…Œê³ ë¦¬ ì •ë³´ í¬í•¨ ì—¬ë¶€
            use_description: ì„¤ëª… ì •ë³´ í¬í•¨ ì—¬ë¶€
            use_features: íŠ¹ì§• ì •ë³´ í¬í•¨ ì—¬ë¶€
            use_last_item: ë§ˆì§€ë§‰ ì•„ì´í…œ ê°•ì¡° ì—¬ë¶€
            use_date: ë‚ ì§œ ì •ë³´ í¬í•¨ ì—¬ë¶€
            max_history_len: ìµœëŒ€ íˆìŠ¤í† ë¦¬ ê¸¸ì´
            history_text_max_length: íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ìµœëŒ€ ë‹¨ì–´ ìˆ˜ (review textì—ë„ ì ìš©)
            use_reviews: ë¦¬ë·° í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€
            days_filter: ìµœê·¼ Nì¼ ì´ë‚´ì˜ ë¦¬ë·°ë§Œ í¬í•¨ (Noneì´ë©´ í•„í„°ë§ ì•ˆí•¨)
        """
        self.item_metadata = item_metadata
        self.data_name = data_name
        self.use_brand = use_brand
        self.use_category = use_category
        self.use_description = use_description
        self.use_features = use_features
        self.use_last_item = use_last_item
        self.use_date = use_date
        self.max_history_len = max_history_len
        self.history_text_max_length = history_text_max_length
        self.use_reviews = use_reviews
        self.days_filter = days_filter
        
        # í”„ë¡¬í”„íŠ¸ íƒ€ì… ì„¤ì •
        if prompt_type not in self.PROMPT_TEMPLATES:
            print(f"âš ï¸  Unknown prompt type '{prompt_type}'. Available types: {list(self.PROMPT_TEMPLATES.keys())}")
            print(f"   Using default 'recent_preference' type.")
            self.prompt_type = 'recent_preference'
        else:
            self.prompt_type = prompt_type
            print(f"âœ“ Using prompt type: '{self.prompt_type}'")
        
        # user2reviews_with_date.json ë¡œë“œ
        self.user_reviews_with_date = {}
        if data_name:
            date_file_path = f"data/{data_name}/user2reviews_with_date.json"
            if os.path.exists(date_file_path):
                print(f"Loading date information from: {date_file_path}")
                with open(date_file_path, 'r') as f:
                    self.user_reviews_with_date = json.load(f)
                print(f"âœ“ Loaded date information for {len(self.user_reviews_with_date)} users")
            else:
                print(f"âš ï¸  Date file not found: {date_file_path}. Dates will not be included.")
                self.use_date = False
    
    def generate_prompt(self, item_ids: List[int], user_id: Optional[int] = None, target_timestamp: Optional[int] = None) -> str:
        """
        ì‚¬ìš©ì ì‹œí€€ìŠ¤ë¡œë¶€í„° í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            item_ids: ì•„ì´í…œ ID ë¦¬ìŠ¤íŠ¸
            user_id: ì‚¬ìš©ì ID (ë‚ ì§œ ì •ë³´ ì¡°íšŒìš©, ì„ íƒì )
            target_timestamp: íƒ€ê²Ÿ íƒ€ì„ìŠ¤íƒ¬í”„ (days_filter ì ìš©ì‹œ ê¸°ì¤€, ì„ íƒì )
        
        Returns:
            ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        # ì‚¬ìš©ìì˜ ë¦¬ë·° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        user_reviews = []
        if user_id is not None:
            user_id_str = str(user_id)
            user_reviews = self.user_reviews_with_date.get(user_id_str, [])
        
        # ì•„ì´í…œ IDë¥¼ í‚¤ë¡œ í•˜ëŠ” ë¦¬ë·° ë§¤í•‘ ìƒì„±
        item_to_review = {}
        if user_reviews:
            for review in user_reviews:
                item_id = int(review.get('item_id', -1))
                if item_id != -1:
                    item_to_review[item_id] = review
        
        # íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        history_text_list = []
        
        # ê° ì•„ì´í…œ ì²˜ë¦¬
        for idx, item_id in enumerate(item_ids):
            item_data = self.item_metadata.get(item_id)
            if item_data is None:
                # ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
                continue
            
            # ì‹œê°„ í•„í„°ë§ (days_filterê°€ ì„¤ì •ë˜ì–´ ìˆê³  target_timestampê°€ ì£¼ì–´ì§„ ê²½ìš°)
            if self.days_filter is not None and target_timestamp is not None and item_id in item_to_review:
                review = item_to_review[item_id]
                timestamp = int(review.get('timestamp', 0))
                if target_timestamp - timestamp > self.days_filter * 24 * 60 * 60:
                    continue
            
            item_title = item_data.get('title', 'Unknown Item')
            item_brand = item_data.get('brand', 'Unknown Brand')
            item_categories = item_data.get('category', 'Unknown Category')
            item_description = item_data.get('description', '')
            
            # reasoning íƒ€ì…ì¼ ê²½ìš° ê°„ë‹¨í•œ í¬ë§·
            if self.prompt_type == "reasoning":
                item_history_text = f"{idx+1}) {item_title} "
            else:
                item_history_text = ""
                # ë‚ ì§œ ì •ë³´ ì¶”ê°€
                if self.use_date and item_id in item_to_review:
                    item_date = item_to_review[item_id].get('date', '')
                    if item_date:
                        item_history_text += f"Date: {item_date}\n"
                
                # ê¸°ë³¸ íˆìŠ¤í† ë¦¬ í¬ë§·
                item_history_text += f"Item Title: {item_title}\n"
                
                if self.use_brand:
                    item_history_text += f"Brand: {item_brand}\n"
                
                if self.use_category:
                    item_history_text += f"Categories: {item_categories}\n"
                
                if self.use_description and item_description:
                    item_description = item_description.replace("\n", " ")
                    if len(item_description.split()) > self.history_text_max_length:
                        item_description = " ".join(
                            item_description.split()[:self.history_text_max_length]
                        ) + "..."
                    item_history_text += f"Description: {item_description}\n"
                
                if self.use_features and item_features:
                    if len(item_features.split("\n")) > 10:
                        item_features = "\n".join(item_features.split("\n")[:10])
                    item_features = item_features.replace("\n-", ",").replace("- ", "")
                    item_history_text += f"Features:\n{item_features}\n"
            
            # ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ê°€
            if self.use_reviews and item_id in item_to_review:
                review_text = item_to_review[item_id].get('text', '')
                # limit review text words
                if review_text and len(review_text.split()) > self.history_text_max_length:
                    review_text = " ".join(review_text.split()[:self.history_text_max_length])
                if review_text:
                    item_history_text += f"Review:\n{review_text}\n"
            
            if item_history_text:
                history_text_list.append(item_history_text)
        
        # íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ë§ˆì§€ë§‰ ì•„ì´í…œì´ë¼ë„ í¬í•¨
        if len(history_text_list) == 0 and len(item_ids) > 0:
            last_item_id = item_ids[-1]
            item_data = self.item_metadata.get(last_item_id)
            if item_data:
                item_title = item_data.get('title', 'Unknown Item')
                item_brand = item_data.get('brand', 'Unknown Brand')
                
                if self.prompt_type == "reasoning":
                    item_history_text = f"1) {item_title} "
                else:
                    item_history_text = f"Item Title: {item_title}\n"
                    if self.use_brand:
                        item_history_text += f"Brand: {item_brand}\n"
                
                if self.use_reviews and last_item_id in item_to_review:
                    review_text = item_to_review[last_item_id].get('text', '')
                    if review_text and len(review_text.split()) > self.history_text_max_length:
                        review_text = " ".join(review_text.split()[:self.history_text_max_length])
                    if review_text:
                        item_history_text += f"Review:\n{review_text}\n"
                
                history_text_list.append(item_history_text)
        
        # íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œì•½ ì ìš©
        if len(history_text_list) > self.max_history_len:
            history_text_list = history_text_list[-self.max_history_len:]
        
        # ìµœì¢… íˆìŠ¤í† ë¦¬ í…ìŠ¤íŠ¸ êµ¬ì„±
        history_text = "\n\n".join(
            f"{i+1}. {history}" for i, history in enumerate(history_text_list)
        )
        
        # ë§ˆì§€ë§‰ ì•„ì´í…œ ê°•ì¡°
        if self.use_last_item and len(item_ids) > 0:
            last_item = self.item_metadata.get(item_ids[-1], {})
            last_item_title = last_item.get('title', 'Unknown Item')
            history_text += f"\n\n`{last_item_title}` is the most recently purchased item."
        
        # ì„ íƒëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
        template = self.PROMPT_TEMPLATES[self.prompt_type]
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = (
            f"{template['title']}\n\n"
            f"{history_text}\n\n"
            f"{template['task']}\n"
        )
        
        return prompt


class RecommendationDataset(Dataset):
    """
    ì¶”ì²œ ì‹œìŠ¤í…œìš© ë°ì´í„°ì…‹
    ì‚¬ìš©ì íˆìŠ¤í† ë¦¬, íƒ€ê²Ÿ ì•„ì´í…œ, í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨
    """
    
    def __init__(
        self,
        data_name: str,
        item_metadata: Dict,
        prompt_generator: PromptGenerator,
        split: str = "train",
        num_negs: int = 0,
        num_items: Optional[int] = None,
    ):
        """
        Args:
            data_name: ë°ì´í„°ì…‹ ì´ë¦„
            item_metadata: ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            prompt_generator: í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
            split: ë°ì´í„° ë¶„í•  ("train", "valid", "test")
            num_negs: ì‚¬ì „ ìƒ˜í”Œë§í•  negative ì•„ì´í…œ ìˆ˜ (0ì´ë©´ ë¹„í™œì„±í™”)
            num_items: ì „ì²´ ì•„ì´í…œ ìˆ˜ (negative samplingì— í•„ìš”)
        """
        self.item_metadata = item_metadata
        self.prompt_generator = prompt_generator
        self.split = split
        self.num_negs = num_negs
        self.num_items = num_items
        
        sequential_file = f"data/{data_name}/sequential_data.txt"
        self._load_real_data(sequential_file, split)
        
        # í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ ìƒì„± (ì´ˆê¸°í™” ì‹œì )
        print(f"âœï¸  Pre-generating prompts for {len(self.user_ids)} users...")
        self.prompt_dict = {}
        for user_id in self.user_ids:
            history = self.history_dict[user_id]
            self.prompt_dict[user_id] = self.prompt_generator.generate_prompt(history, user_id=user_id)

        # print sample prompts
        for user_id in [10, 20, 30]:
            print(f"User {user_id}: \n{self.prompt_dict[user_id]}")
            print("-" * 100)
        
        # Negative items ë¯¸ë¦¬ ìƒ˜í”Œë§ (ì´ˆê¸°í™” ì‹œì )
        self.neg_items_dict = {}
        if self.num_negs > 0:
            if self.num_items is None:
                raise ValueError("num_items must be provided when num_negs > 0")
            print(f"ğŸ² Pre-sampling {self.num_negs} negative items for each user...")
            self._sample_negative_items()
        
        print(f"âœ“ {split.upper()} Dataset loaded: {len(self.user_ids)} users")
    
    def _load_real_data(
        self,
        sequential_file: str,
        split: str,
    ):
        """ì‹¤ì œ ë°ì´í„° ë¡œë“œ"""
        all_user_ids = []
        all_history = {}
        all_targets = {}
        
        if split == "train":
            target_index = -3
        elif split == "valid":
            target_index = -2
        elif split == "test":
            target_index = -1
        else:
            raise ValueError(f"Invalid split: {split}")
        
        with open(sequential_file, "r") as f:
            for line in f:
                parts = [int(p) for p in line.strip().split()]
                user_id = parts[0]
                history = parts[1:target_index]
                target = parts[target_index]
                
                all_user_ids.append(user_id)
                all_history[user_id] = history
                all_targets[user_id] = target
        
        self.user_ids = all_user_ids
        self.history_dict = all_history
        self.target_dict = all_targets
    
    def _sample_negative_items(self):
        """ê° ì‚¬ìš©ìë³„ë¡œ negative items ì‚¬ì „ ìƒ˜í”Œë§"""
        rng = np.random.RandomState(42)  # ì¬í˜„ì„±ì„ ìœ„í•œ ê³ ì • seed
        
        for user_id in self.user_ids:
            history = self.history_dict[user_id]
            target = self.target_dict[user_id]
            
            # ì œì™¸í•  ì•„ì´í…œ (history + target)
            excluded = set(history + [target])
            
            # ê°€ëŠ¥í•œ negative items (ì „ì²´ ì•„ì´í…œ - ì œì™¸ ì•„ì´í…œ)
            all_items = set(range(self.num_items))
            candidate_items = list(all_items - excluded)
            
            # ëœë¤ ìƒ˜í”Œë§
            if len(candidate_items) >= self.num_negs:
                neg_items = rng.choice(candidate_items, size=self.num_negs, replace=False).tolist()
            else:
                # í›„ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš° ì¤‘ë³µ ìƒ˜í”Œë§
                neg_items = rng.choice(candidate_items, size=self.num_negs, replace=True).tolist()
            
            self.neg_items_dict[user_id] = neg_items
    
    def __len__(self):
        return len(self.user_ids)
    
    def __getitem__(self, idx):
        user_id = self.user_ids[idx]
        history = self.history_dict[user_id]
        target = self.target_dict[user_id]
        
        # ë¯¸ë¦¬ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt = self.prompt_dict[user_id]
        
        result = {
            "prompt": prompt,
            "history": history,
            "target": target,
            "user_id": user_id,
        }
        
        # Negative itemsê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if self.num_negs > 0:
            result["neg_items"] = self.neg_items_dict[user_id]
        
        return result


def collate_fn(batch):
    """
    DataLoaderìš© collate function
    """
    return {
        "queries": [item["query"] for item in batch],
        "histories": [item["history"] for item in batch],
        "targets": [item["target"] for item in batch],
        "user_ids": [item["user_id"] for item in batch],
    }


def load_item_metadata(dataset_name: str, data_dir: str = "data") -> Dict:
    """
    ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    
    Args:
        dataset_name: ë°ì´í„°ì…‹ ì´ë¦„ (e.g., "beauty")
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
    
    Returns:
        ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì‹œë„
    possible_paths = [
        f"{data_dir}/{dataset_name}/meta_text.json",
    ]
    
    item_metadata = {}
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"Loading item metadata from: {path}")
            
            if path.endswith('.json'):
                with open(path, 'r') as f:
                    data = json.load(f)
                    # Keyë¥¼ intë¡œ ë³€í™˜
                    item_metadata = {int(k): v for k, v in data.items()}
            elif path.endswith('.pkl'):
                with open(path, 'rb') as f:
                    item_metadata = pickle.load(f)
            
            print(f"âœ“ Loaded {len(item_metadata)} items")
            return item_metadata
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ê²½ê³ 
    print(f"âš ï¸  Item metadata file not found. Using dummy metadata.")
    return {}


def create_dataloaders(
    args: argparse.Namespace,
) -> Tuple[DataLoader, DataLoader, DataLoader, PromptGenerator, Dict]:
    """
    Train/Valid/Test DataLoader ìƒì„±
    
    Args:
        args: argparse.Namespace
    
    Returns:
        (train_dataloader, valid_dataloader, test_dataloader, prompt_generator, item_metadata)
    """
    # ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“¦ Loading item metadata...")
    item_metadata = load_item_metadata(args.dataset_name)
    
    # num_items ê°€ì ¸ì˜¤ê¸° (argsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¶”ì¶œ)
    num_items = getattr(args, 'num_items', None)
    if num_items is None and len(item_metadata) > 0:
        num_items = max(item_metadata.keys()) + 1
        print(f"  Inferred num_items from metadata: {num_items}")
    
    # num_negs ê°€ì ¸ì˜¤ê¸° (argsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0)
    num_negs = getattr(args, 'num_negs', 0)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
    print(f"âœï¸  Creating prompt generator...")
    
    # use_date íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (argsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ True)
    use_date = getattr(args, 'use_date', True)
    
    # prompt_type íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (argsì— ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 'recent_preference')
    prompt_type = getattr(args, 'prompt_type', 'seq_rec')
    
    prompt_generator = PromptGenerator(
        item_metadata=item_metadata,
        data_name=args.dataset_name,
        prompt_type=prompt_type,
        use_brand=args.use_brand,
        use_category=args.use_category,
        use_description=args.use_description,
        use_date=use_date,
        max_history_len=args.max_history_len,
        history_text_max_length=args.history_text_max_length,
    )
    
    # ë°ì´í„°ì…‹ ìƒì„±
    print(f"ğŸ“Š Creating datasets...")
    
    # Train dataset
    train_dataset = RecommendationDataset(
        data_name=args.dataset_name,
        item_metadata=item_metadata,
        prompt_generator=prompt_generator,
        split="train",
        num_negs=num_negs,
        num_items=num_items,
    )
    
    # Valid dataset
    valid_dataset = RecommendationDataset(
        data_name=args.dataset_name,
        item_metadata=item_metadata,
        prompt_generator=prompt_generator,
        split="valid",
        num_negs=num_negs,
        num_items=num_items,
    )
    
    # Test dataset
    test_dataset = RecommendationDataset(
        data_name=args.dataset_name,
        item_metadata=item_metadata,
        prompt_generator=prompt_generator,
        split="test",
        num_negs=num_negs,
        num_items=num_items,
    )
    
    # DataLoaders
    print(f"ğŸ”„ Creating dataloaders...")
    
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        collate_fn=collate_fn,
    )
    
    valid_dataloader = DataLoader(
        valid_dataset,
        batch_size=args.eval_batch_size,
        shuffle=False,
        collate_fn=collate_fn,
    )
    
    test_dataloader = DataLoader(
        test_dataset,
        batch_size=args.eval_batch_size,
        shuffle=False,
        collate_fn=collate_fn,
    )
    
    print(f"âœ“ DataLoaders created:")
    print(f"  Train samples: {len(train_dataset)}")
    print(f"  Valid samples: {len(valid_dataset)}")
    print(f"  Test samples: {len(test_dataset)}")
    if num_negs > 0:
        print(f"  Negative samples per user: {num_negs}")
    
    return train_dataset, valid_dataset, test_dataset, prompt_generator, item_metadata
    # return train_dataloader, valid_dataloader, test_dataloader, prompt_generator, item_metadata

