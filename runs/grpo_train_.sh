#!/bin/bash
# GRPO í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

# set -e

# # ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™
# cd "$(dirname "$0")/.."

# echo "ğŸš€ Starting GRPO Training for RL4Rec"
# echo "========================================"

# # Ray í´ëŸ¬ìŠ¤í„° í™•ì¸
# echo "ğŸ“¡ Checking Ray cluster..."
# ray status || {
#     echo "âš ï¸  Ray cluster not found. Please start retrieval service first:"
#     echo "   ./runs/run_retrieval.sh"
#     exit 1
# }

# # Python ê²½ë¡œ ì„¤ì •
# export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"

# í•™ìŠµ ì‹¤í–‰
CUDA_VISIBLE_DEVICES=7 python3 src/grpo_train.py \
    --policy_model "google/gemma-3-1b-it" \
    --data_name "beauty" \
    --sequential_file "data/beauty/sequential_data.txt" \
    --reward_type "ndcg" \
    --k 1000 \
    --batch_size 32 \
    --num_sample_generations 4 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1e-6 \
    --num_epochs 1 \
    --max_steps 3000 \
    --max_length 512 \
    --use_brand \
    --use_category \
    --checkpoint_dir "checkpoints/grpo" \
    --log_interval 10 \
    --eval_interval 100 \
    --save_interval 500 \
    --num_negs 0 \
    --device "cuda" \
    --normalize_rewards \
    "$@"

echo "âœ… Training completed!"

